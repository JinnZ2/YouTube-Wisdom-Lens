# %% [markdown]
# #  YouTube Wisdom Lens Prototype
# **A culturally-aware AI video analyzer**
# 
# Version 0.1 â€“ Cultural Context & Bias Detection

# %% [markdown]
# ## 1. Install Dependencies

!pip install -q google-api-python-client transformers langdetect sentence-transformers pandas youtube-transcript-api spacy nltk
!python -m nltk.downloader punkt
!python -m spacy download en_core_web_sm

# %% [markdown]
# ## 2. Set Up YouTube API

from googleapiclient.discovery import build

API_KEY = "YOUR_API_KEY"  # Replace this with your actual API key
youtube = build('youtube', 'v3', developerKey=API_KEY)

def get_video_context(video_id):
    request = youtube.videos().list(
        part="snippet,contentDetails,statistics",
        id=video_id
    )
    return request.execute()

# %% [markdown]
# ## 3. Load CulturalLens Class

from cultural_lens import CulturalLens

lens = CulturalLens()

# %% [markdown]
# ## 4. Load Fact Verifier

from fact_verifier import verify_claim

# %% [markdown]
# ## 5. Load Sensitivity Checker

from sensitivity_check import cultural_sensitivity_check

# %% [markdown]
# ## 6. Basic Title Analysis

import pandas as pd

video_id = "dQw4w9WgXcQ"  # Replace with target YouTube video ID

video_data = get_video_context(video_id)
title = video_data['items'][0]['snippet']['title']

cultural_analysis = lens.analyze(title)
fact_check = verify_claim(title)
sensitivity = cultural_sensitivity_check(title)

print("Title:", title)
print("\n Cultural Analysis:")
print(pd.Series(cultural_analysis))
print("\n Fact Check:")
print(pd.Series(fact_check))
print("\n Sensitivity Check:", sensitivity)

# %% [markdown]
# ## 7. Transcript NLP Analysis

from transcript_nlp_pipeline import get_transcript, analyze_transcript

transcript = get_transcript(video_id)

if transcript:
    transcript_results = analyze_transcript(transcript)
    for i, entry in enumerate(transcript_results[:5]):  # show 5 chunks
        print(f"\n=== Segment {i+1} ===")
        print("Text:", entry["text"])
        print("Language:", entry["lang"])
        print("Perspective:", entry["perspective"])
        print("Cultural Markers:", entry["markers"])
        print("Warnings:", entry["warnings"])
        print("Sensitivity:", entry["sensitivity"])
        print("Fact Check Verdict:", entry["fact_check"]["verdict"])
        print("Consensus Score:", round(entry["fact_check"]["consensus_score"], 2))

# %% [markdown]
# ## 8. Summary and Next Steps
# - Expand cultural marker database (`cultural_lens.py`)
# - Visualize results in HTML dashboard
# - Analyze transcripts across multiple videos
# - Add audio/video fingerprinting for visual bias detection
# 
# **Built by JinnZ2 + ChatGPT**
